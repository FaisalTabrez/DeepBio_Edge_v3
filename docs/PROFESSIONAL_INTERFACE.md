# Global-BioScan Professional Interface Documentation

## Version 3.0 - Professional Scientific Nomenclature

### Overview

This document describes the **overhauled professional interface** for the Global-BioScan Genomic Analysis Platform. The interface has been transformed from a demonstration prototype into a **production-ready biotechnology application** meeting international scientific standards.

---

## Key Improvements

### 1. **Scientific Nomenclature Compliance**

All informal terminology has been replaced with professional scientific nomenclature:

| **Old Term (Demo)**          | **New Term (Professional)**              |
|------------------------------|------------------------------------------|
| Deep Sea Detective           | Taxonomic Inference Engine               |
| Discovery Manifold           | Latent Space Analysis                    |
| Biodiversity Report          | Ecological Composition Analysis          |
| "Analyze Sequence"           | "Execute Inference"                      |
| "Try a Mystery Sequence"     | "Load Reference Template"                |
| "Similarity Threshold"       | "Identity Confidence Threshold (Ïƒ)"      |

### 2. **Universal Sequence Ingestion System**

The interface now supports **5 standard bioinformatics file formats**:

- **FASTA** (`.fasta`, `.fa`, `.fna`) - Sequences with headers
- **FASTQ** (`.fastq`, `.fq`) - Sequences with quality scores
- **CSV** (`.csv`) - Tabular data with sequence columns
- **TXT** (`.txt`) - Plain text sequences
- **Parquet** (`.parquet`) - Columnar binary format for large datasets

#### **Parsing Logic**

The new `parse_bio_file()` helper function:
- Automatically detects file format from extension
- Uses BioPython `SeqIO` for FASTA/FASTQ parsing
- Intelligently identifies sequence columns in CSV/Parquet
- Validates nucleotide sequences (IUPAC codes)
- Returns standardized records: `{'id': '...', 'sequence': '...'}`

### 3. **Batch Processing Mode**

New capabilities for high-throughput analysis:

- **Single Sequence Mode**: Traditional one-at-a-time processing
- **Batch Processing Mode**: Vectorized inference for multiple sequences

**Batch Pipeline:**
1. **Stage 1/3**: Vectorized embedding generation (GPU-accelerated if available)
2. **Stage 2/3**: Parallel vector database searches
3. **Stage 3/3**: Summary report generation with metrics

**Features:**
- Real-time progress bars with `st.progress()`
- Stage-based status updates with `st.status()`
- Batch summary table with confidence scores
- Classification statistics (High Confidence, Known Taxa, Novel Candidates)

### 4. **Darwin Core Compliance**

Results can be exported in **Darwin Core** standard format for biodiversity databases:

**Darwin Core Mappings:**
- `id` â†’ `occurrenceID`
- `sequence` â†’ `associatedSequences`
- `predicted_lineage` â†’ `scientificName`
- `confidence` â†’ `identificationRemarks`
- `status` â†’ `occurrenceStatus`

**Metadata Added:**
- `basisOfRecord`: "MachineObservation"
- `identificationMethod`: "Nucleotide Transformer Deep Learning Model"
- `dateIdentified`: Current timestamp

**Export Button:**
```python
st.download_button(
    label="ðŸ“¥ Download Darwin Core CSV",
    data=export_darwin_core_csv(results),
    file_name=f"bioscan_results_{timestamp}.csv"
)
```

### 5. **Professional UI Refinements**

#### **Color Palette**
- Background: `#0a1929` (Deep Navy)
- Sidebar: `#132f4c` (Dark Blue-Gray)
- Accents: `#66d9ef` (Cyan) for headers
- Buttons: `#1976d2` (Material Blue)

#### **Status Indicators**
- ðŸŸ¢ **Online/Ready**: System operational
- ðŸ”´ **Offline/Error**: Connection failed
- ðŸŸ¡ **Unavailable**: Component not loaded

#### **Confidence Color Coding**
- ðŸŸ¢ Green: > 0.9 (High Confidence)
- ðŸŸ¡ Yellow: 0.7-0.9 (Moderate Confidence)
- ðŸ”´ Red: < 0.7 (Low Confidence)

#### **Interactive Elements**
- `st.status()` for real-time operation logs
- `st.progress()` for batch processing stages
- `st.column_config.ProgressColumn` for confidence bars
- Expandable preview sections with `st.expander()`

### 6. **Advanced Sidebar Metrics**

Professional system monitoring dashboard:

**System Status:**
- Vector Database: Connection state
- ML Model: Availability status

**Database Metrics:**
- Sequences Indexed: Total count in vector store
- Novel Taxa Detected: Novelty candidates found

**Inference Parameters:**
- Identity Confidence Threshold (Ïƒ): 0.0-1.0 slider
- K-Nearest Neighbors: 1-50 slider

**Model Architecture:**
```
Model: Nucleotide Transformer
Parameters: 500M (500 Million)
Embedding Dimension: 768
Context Window: 6,000 nucleotides
Pre-training: Multi-species genomic corpus
```

**Backend Infrastructure:**
```
Vector Store: LanceDB (Disk-Native)
Index Type: IVF-PQ (Inverted File Index)
Storage: 32GB Pendrive (Edge Deployment)
Similarity Metric: Cosine Distance
```

---

## Tab Descriptions

### Tab 1: Taxonomic Inference Engine

**Purpose:** Execute deep learning-based taxonomic classification on DNA sequences.

**Features:**
1. **Processing Mode Selection:**
   - Single Sequence: Traditional inference
   - Batch Processing: Vectorized multi-sequence analysis

2. **Input Methods:**
   - File Upload: Drag-and-drop for `.fasta`, `.fastq`, `.csv`, `.txt`, `.parquet`
   - Manual Entry: Text area with validation

3. **Quick Actions:**
   - ðŸ“‹ Load Reference Template: Insert example sequence
   - ðŸ—‘ï¸ Clear: Reset input field

4. **Execution Pipeline:**
   - Sequence validation (IUPAC codes)
   - Embedding generation (768-dimensional)
   - Vector database search (cosine similarity)
   - Taxonomic lineage prediction

5. **Results Display:**
   - Classification metrics (confidence, status)
   - K-Nearest Reference Sequences table
   - Batch summary statistics
   - Darwin Core CSV export

### Tab 2: Latent Space Analysis

**Purpose:** Interactive visualization of high-dimensional genomic embeddings.

**Features:**
1. **Dimensionality Reduction:**
   - t-SNE: Non-linear manifold learning
   - PCA: Linear projection (faster)
   - UMAP: Uniform Manifold Approximation (planned)

2. **3D Scatter Plot:**
   - Interactive rotation with Plotly
   - Color-coded by phylum
   - Hover tooltips with sequence ID
   - Dark theme optimized for scientific viewing

3. **Sampling Controls:**
   - Sample size slider (100-10,000 vectors)
   - Database connection monitoring

### Tab 3: Ecological Composition Analysis

**Purpose:** Comprehensive biodiversity assessment and taxonomic distribution.

**Features:**
1. **Summary Metrics:**
   - Total Sequences
   - Unique Species
   - Unique Genera
   - Unique Phyla

2. **Distribution Charts:**
   - Phylum Abundance: Top 10 bar chart
   - Class Abundance: Top 10 bar chart
   - Interactive Plotly visualizations

3. **Taxonomic Inventory:**
   - Hierarchical table (Kingdom â†’ Phylum â†’ Class â†’ Order)
   - Sortable by abundance
   - Full scrollable view

---

## File Format Examples

### FASTA Format
```
>sequence_001 | Description here
ATGCGATCGATCGATCGATCGATCGATCGATCG
>sequence_002 | Another description
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC
```

### FASTQ Format
```
@sequence_001
ATGCGATCGATCGATCGATCGATCGATCGATCG
+
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@sequence_002
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC
+
JJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ
```

### CSV Format
```csv
sequence_id,sequence,source,date
SEQ_001,ATGCGATCGATCG...,Marine,2024-01-15
SEQ_002,GCTAGCTAGCTAG...,Soil,2024-01-16
```

**Requirements:**
- Must have a column with "seq" in the name (case-insensitive)
- Optional ID column (defaults to first column)

### TXT Format
```
ATGCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC
TACGTACGTACGTACGTACGTACGTACGTACGTA
```

**Rules:**
- One sequence per line
- Lines starting with `#` are treated as comments
- Empty lines are skipped

### Parquet Format
- Same structure as CSV but in columnar binary format
- Efficient for large datasets (>1GB)
- Requires `pyarrow` library

---

## Usage Workflows

### Workflow 1: Single Sequence Analysis

1. Open **Taxonomic Inference Engine** tab
2. Select **"Manual Entry"**
3. Paste DNA sequence in text area
4. Click **"Execute Inference"**
5. Review:
   - Predicted lineage
   - Confidence score
   - K-nearest neighbors table

### Workflow 2: Batch File Processing

1. Open **Taxonomic Inference Engine** tab
2. Select **"Batch Processing"** mode
3. Upload FASTA/FASTQ/CSV file
4. Review sequence preview
5. Click **"Execute Inference"**
6. Monitor progress bar (3 stages)
7. Review batch summary:
   - Total sequences processed
   - High confidence count
   - Known taxa vs. novel candidates
8. Download **Darwin Core CSV** for database submission

### Workflow 3: Latent Space Exploration

1. Open **Latent Space Analysis** tab
2. Adjust sample size (e.g., 1,000 vectors)
3. Select dimensionality reduction (t-SNE recommended)
4. Wait for visualization to load
5. Interact with 3D plot:
   - Rotate: Click and drag
   - Zoom: Scroll wheel
   - Hover: See sequence IDs

### Workflow 4: Ecological Assessment

1. Open **Ecological Composition** tab
2. Review summary metrics (species, genera, phyla counts)
3. Examine distribution charts:
   - Phylum abundance
   - Class abundance
4. Scroll through taxonomic inventory table
5. Identify dominant clades and rare taxa

---

## Technical Specifications

### Dependencies

**Core:**
- `streamlit` >= 1.30.0 - Web interface framework
- `lancedb` >= 0.5.0 - Vector database
- `numpy` >= 1.24.0 - Numerical computing
- `pandas` >= 2.0.0 - Data manipulation

**Visualization:**
- `plotly` >= 5.18.0 - Interactive charts
- `matplotlib` >= 3.8.0 - Static plots

**Machine Learning:**
- `torch` >= 2.1.0 - PyTorch (with triton mocking for Windows)
- `transformers` >= 4.35.0 - Hugging Face models
- `scikit-learn` >= 1.3.0 - Dimensionality reduction

**Bioinformatics:**
- `biopython` >= 1.81 - Sequence parsing (FASTA/FASTQ)

### System Requirements

**Minimum:**
- CPU: 4 cores
- RAM: 8 GB
- Storage: 10 GB free
- OS: Windows 10/11, Linux, macOS

**Recommended:**
- CPU: 8+ cores
- RAM: 16 GB
- GPU: NVIDIA with 6GB+ VRAM (optional, for accelerated embeddings)
- Storage: 32 GB USB 3.0 drive for database

**Browser:**
- Chrome/Edge (recommended)
- Firefox
- Safari (limited 3D support)

### Performance Benchmarks

| **Operation**              | **Single Sequence** | **Batch (100 seqs)** |
|----------------------------|---------------------|----------------------|
| File parsing               | <1 sec              | 2-5 sec              |
| Embedding generation       | 0.5 sec (GPU)       | 10 sec (GPU)         |
| Vector search              | 0.1 sec             | 2 sec                |
| Total inference time       | ~1 sec              | ~15 sec              |

*Benchmarks on: Intel i7, 16GB RAM, NVIDIA RTX 3060*

---

## Troubleshooting

### Issue: "BioPython required for FASTA parsing"
**Solution:** Install biopython:
```bash
pip install biopython
```

### Issue: "Could not find sequence column"
**Solution:** CSV/Parquet files must have a column with "seq" in the name (e.g., "sequence", "seq", "DNA_seq")

### Issue: "Embedding engine unavailable"
**Solution:** 
1. Check transformers installation: `pip install transformers torch`
2. On Windows, triton will be automatically mocked
3. Fallback to mock embeddings if GPU unavailable

### Issue: "Port 8501 already in use"
**Solution:** Use a different port:
```bash
streamlit run src/interface/app.py --server.port 8502
```

### Issue: "LanceDB connection failed"
**Solution:** Verify database path in `src/config.py`:
```python
LANCEDB_PENDRIVE_PATH = Path("path/to/your/database")
```

---

## Demo Data

Sample files are provided in `data/demo/`:

1. **sample_sequences.fasta** - 5 FASTA sequences from diverse taxa
2. **sample_sequences.csv** - 5 CSV records with metadata

**Quick Test:**
1. Launch app: `streamlit run src/interface/app.py`
2. Navigate to Taxonomic Inference Engine
3. Upload `data/demo/sample_sequences.fasta`
4. Click "Execute Inference"
5. Review batch results

---

## Citation

If you use Global-BioScan in your research, please cite:

```
DeepBio-Edge: Large-scale Biodiversity Monitoring via Foundation Models on Edge Devices
Global-BioScan Consortium (2026)
[DOI: Pending]
```

---

## License

MIT License - See LICENSE file for details

---

## Support

For technical support or feature requests:
- GitHub Issues: [repository-url]
- Email: support@globalbioscan.org
- Documentation: [docs-url]

---

**Last Updated:** 2026-01-25  
**Version:** 3.0.0-professional  
**Status:** Production Ready âœ…
