# Global-BioScan: End-to-End Integration Guide

## Project Phases

### Phase 1: Data Ingestion âœ…
**Status:** Complete  
**Script:** `run_ingestion.py`  
**Output:** LanceDB with DNA sequences + metadata + placeholder vectors

### Phase 2: Embedding Generation âœ… (JUST COMPLETED)
**Status:** Complete  
**Script:** `run_embeddings.py`  
**Output:** LanceDB updated with 768-dim biological embeddings

### Phase 3: Novelty Detection ğŸ”„ (NEXT)
**Status:** In Progress  
**Script:** `src/edge/taxonomy.py` (to be implemented)  
**Tasks:**
- Run HDBSCAN clustering on embeddings
- Compute distances to cluster centroids
- Assign novelty scores
- Infer novel taxonomic units

### Phase 4: Visualization ğŸ”„ (NEXT)
**Status:** Ready for Implementation  
**Script:** `src/interface/app.py`  
**Pages:**
- Dashboard: Overview + statistics
- Embedding Explorer: UMAP + vector search
- Novelty Detection: Novel taxa results
- Diversity Metrics: Alpha/Beta diversity
- Configuration: Settings panel

---

## Complete Workflow

### Prerequisites
1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set Environment**
   ```bash
   # .env file
   NCBI_EMAIL=your-email@example.com
   NCBI_API_KEY=your-api-key  # Optional but recommended
   BIOSCANSCAN_DB_DRIVE=E:\GlobalBioScan_DB  # Pendrive location
   ```

3. **Prepare Hardware**
   - Ensure 32GB pendrive mounted at `E:\` (or custom path)
   - Check internet connection for API access
   - GPU optional but recommended

### Full Pipeline

```bash
# 1. INGEST DATA (fetch OBIS + NCBI sequences)
# Time: ~5-10 minutes for 100 species
# Output: 100 sequences in LanceDB with metadata
python run_ingestion.py --max-species 100 --db-drive "E:\GlobalBioScan_DB"

# 2. GENERATE EMBEDDINGS (NT-500M transformations)
# Time: ~30 min (CPU), ~5 min (GPU)
# Output: All sequences now have 768-dim vectors
python run_embeddings.py --batch-size 8

# 3. DETECT NOVELTY (HDBSCAN clustering + scoring)
# Time: ~1 minute
# Output: Novelty scores, cluster assignments, inferred taxonomy
python run_novelty.py  # TODO: create this script

# 4. VISUALIZE (Streamlit dashboard)
# Output: Interactive exploration interface
streamlit run src/interface/app.py
```

---

## Phase 1: Data Ingestion (COMPLETED)

### What Happens
```
OBIS API
  â†“ (1000s occurrences at depth > 1000m)
  â†“
Species Deduplication
  â†“ (50 unique species)
  â†“
NCBI Entrez (fetch sequences)
  â†“ (45 species have COI/18S)
  â†“
TaxonKit (normalize taxonomy)
  â†“ (7-level lineage)
  â†“
LanceDB Storage
  â”œâ”€ sequence_id
  â”œâ”€ dna_sequence (raw nucleotides)
  â”œâ”€ vector (placeholder: zeros)  â† Will be filled by Phase 2
  â”œâ”€ taxonomy (NCBI lineage)
  â”œâ”€ depth, lat/lon
  â””â”€ metadata
```

### Files
- **[src/edge/init_db.py](src/edge/init_db.py)** - Implementation
- **[run_ingestion.py](run_ingestion.py)** - Entry point
- **[tests/test_init_db.py](tests/test_init_db.py)** - Tests
- **[docs/DATA_INGESTION.md](docs/DATA_INGESTION.md)** - Detailed docs

### Usage
```bash
# Full workflow
python run_ingestion.py

# Test components
python tests/test_init_db.py obis      # Test OBIS fetching
python tests/test_init_db.py ncbi      # Test NCBI Entrez
python tests/test_init_db.py full      # Full pipeline (5 species)
```

### Output Example
```
LanceDB Table: sequences
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sequence_id     â”‚ dna_sequence    â”‚ vector              â”‚ depth â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OBIS_COI_AB1234 â”‚ ATGCATGC...     â”‚ [0.0, 0.0, ...]    â”‚ 2500  â”‚
â”‚ OBIS_18S_CD5678 â”‚ GCTAGCTA...     â”‚ [0.0, 0.0, ...]    â”‚ 3200  â”‚
â”‚ ...             â”‚ ...             â”‚ ...                 â”‚ ...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 2: Embedding Generation (ğŸ†• COMPLETE)

### What Happens
```
LanceDB Sequences
  â†“ (fetch rows with zero vectors)
  â†“
Tokenization (CharacterTokenizer)
  â”œâ”€ DNA â†’ token IDs
  â”œâ”€ Padding to 1000bp
  â””â”€ Attention masks
  â†“
NT-500M Forward Pass
  â”œâ”€ GPU (FP16) or CPU (FP32)
  â”œâ”€ Extract hidden states (last layer)
  â””â”€ 768-dimensional representation
  â†“
Mean Pooling
  â”œâ”€ Average over sequence dimension
  â”œâ”€ Respects attention mask (ignore padding)
  â””â”€ Final embedding: 768-dim vector
  â†“
LanceDB Update
  â”œâ”€ Write embedding to vector column
  â”œâ”€ Batch insert (10 sequences/batch)
  â”œâ”€ Save checkpoint (resume on interrupt)
  â””â”€ Progress bar (tqdm)
```

### Files
- **[src/edge/embedder.py](src/edge/embedder.py)** - Implementation (500+ lines)
- **[run_embeddings.py](run_embeddings.py)** - Entry point
- **[tests/test_embeddings.py](tests/test_embeddings.py)** - Test suite
- **[docs/EMBEDDING_ENGINE.md](docs/EMBEDDING_ENGINE.md)** - Detailed docs

### Key Features

âœ… **Windows Compatibility**
- Mocks Triton (CUDA kernels) at script top
- Mocks FlashAttention (optimized attention)
- Works on Windows 11 laptop with no special setup

âœ… **GPU/CPU Auto-Detection**
- Detects NVIDIA GPU if available
- Uses FP16 precision on GPU (faster)
- Falls back to FP32 on CPU (compatible)

âœ… **Memory Management**
- Configurable batch size (adjust for RAM)
- Default: 8 sequences/batch (handles 16GB laptops)
- Reduce to 4 if OOM errors

âœ… **Checkpoint/Resume**
- Saves progress after each batch
- Auto-resumes from last checkpoint on restart
- No data loss if interrupted

âœ… **Validation**
- Embeddings semantically meaningful
- Similar sequences (same genus) â†’ high similarity
- Different sequences (different markers) â†’ lower similarity

### Usage

```bash
# Full pipeline (auto-detect GPU/CPU)
python run_embeddings.py

# With custom batch size
python run_embeddings.py --batch-size 4   # For low-RAM systems

# Force CPU
python run_embeddings.py --cpu

# Force GPU
python run_embeddings.py --gpu

# Limit sequences (for testing)
python run_embeddings.py --max-sequences 10

# Validation test only (no LanceDB update)
python run_embeddings.py --validate-only
```

### Python API

```python
from src.edge.embedder import EmbeddingEngine

# Initialize
engine = EmbeddingEngine(batch_size=8)

# Single sequence
embedding = engine.get_embedding_single("ATGCATGC")
# Returns: np.ndarray shape (768,)

# Batch
embeddings = engine.get_embeddings(["ATGC...", "GCTA..."])
# Returns: np.ndarray shape (3, 768)

# Full LanceDB update
stats = engine.embed_and_update_lancedb(
    db_path="E:\\GlobalBioScan_DB\\lancedb",
    max_sequences=100,
    resume=True
)

# Validation
engine.validate_embeddings()
```

### Testing

```bash
# Test all
python tests/test_embeddings.py all

# Test individual components
python tests/test_embeddings.py model      # Model loading
python tests/test_embeddings.py single     # Single embedding
python tests/test_embeddings.py batch      # Batch processing
python tests/test_embeddings.py validation # Cosine similarity
python tests/test_embeddings.py invalid    # Error handling
```

### Performance

| Hardware | Speed | Memory |
|----------|-------|--------|
| CPU (i7) | 5-10 seq/min | 12-14 GB |
| RTX 3060 | 50-100 seq/min | 4-6 GB |

### Output Example

```
LanceDB Table: sequences (UPDATED)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sequence_id     â”‚ vector (768-dim)      â”‚ dna_sequence   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OBIS_COI_AB1234 â”‚ [0.234, -0.156, ...] â”‚ ATGCATGC...    â”‚
â”‚ OBIS_18S_CD5678 â”‚ [-0.087, 0.923, ...] â”‚ GCTAGCTA...    â”‚
â”‚ ...             â”‚ ...                   â”‚ ...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 3: Novelty Detection (NEXT)

### What Will Happen
```
LanceDB Embeddings
  â†“
HDBSCAN Clustering
  â”œâ”€ Unsupervised grouping
  â”œâ”€ Density-based clusters
  â””â”€ Noise points identified
  â†“
Novelty Scoring
  â”œâ”€ Distance to cluster centroid
  â”œâ”€ Percentile-based threshold
  â””â”€ Assign novelty score (0-1)
  â†“
Taxonomy Assignment
  â”œâ”€ Consensus from cluster members
  â”œâ”€ Known species â†’ reference taxonomy
  â”œâ”€ Novel clusters â†’ inferred genus/species
  â””â”€ Confidence scoring
  â†“
Diversity Metrics
  â”œâ”€ Alpha diversity (Shannon, Simpson)
  â”œâ”€ Beta diversity (clustering coefficient)
  â””â”€ Geographic distribution heatmaps
  â†“
LanceDB Storage
  â”œâ”€ novelty_score
  â”œâ”€ cluster_id
  â”œâ”€ proposed_taxonomy
  â””â”€ confidence
```

### Script to Create
- **[src/edge/taxonomy.py](src/edge/taxonomy.py)** (needs completion)

---

## Phase 4: Visualization (NEXT)

### Dashboard Pages

1. **Dashboard**
   - Total sequences ingested
   - Species diversity
   - Novel taxa discovered
   - Geographic heatmap

2. **Embedding Explorer**
   - UMAP projection of 768-dim vectors
   - Interactive scatter plot
   - Color by: species, novelty, marker gene
   - Hover: sequence info

3. **Vector Search**
   - Upload query sequence
   - Find similar sequences
   - Return top-K matches
   - Display similarity scores

4. **Novelty Detection**
   - Table of novel taxa
   - Proposed taxonomy
   - Confidence scores
   - Phylogenetic tree

5. **Diversity Metrics**
   - Alpha diversity chart (Shannon/Simpson)
   - Beta diversity heatmap
   - Geographic distribution map
   - Depth distribution

6. **Configuration**
   - Model settings
   - Database path
   - API credentials
   - Export options

### Script Location
- **[src/interface/app.py](src/interface/app.py)** (needs completion)

---

## Troubleshooting

### "CUDA out of memory"
```bash
python run_embeddings.py --batch-size 4 --cpu
```

### "No module named 'triton'"
This is expected on Windows. The script automatically mocks it. If you see an import error instead of just a warning, check that the mocking code is at the **very top** of `embedder.py`.

### "LanceDB table not found"
```bash
python run_ingestion.py  # Run Phase 1 first
```

### "Model download fails"
```bash
# Manual pre-download
python -c "
from transformers import AutoModel, AutoTokenizer
model_name = 'InstaDeepAI/nucleotide-transformer-500m-1000-multi-species'
AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
AutoModel.from_pretrained(model_name, trust_remote_code=True)
"
```

---

## Timeline

**Phase 1 (Complete):** Data Ingestion
- Fetch OBIS occurrences
- Retrieve NCBI sequences
- Normalize taxonomy with TaxonKit
- Store in LanceDB

**Phase 2 (Complete):** Embedding Generation
- Load NT-500M model
- Generate 768-dim vectors
- Update LanceDB with embeddings
- Validate semantic similarity

**Phase 3 (Next):** Novelty Detection
- HDBSCAN clustering
- Novelty scoring
- Taxonomy assignment
- Diversity metrics

**Phase 4 (Next):** Dashboard & Visualization
- Streamlit interface
- UMAP exploration
- Vector search
- Real-time results

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Global-BioScan Pipeline                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Phase 1: Data Ingestion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                â”‚
â”‚  OBIS API â”€â”€> NCBI Entrez â”€â”€> TaxonKit        â”‚
â”‚         â†“              â†“            â†“          â”‚
â”‚    (occurrences)  (sequences)   (taxonomy)    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                        â†“                       â”‚
â”‚                  LanceDB Table                â”‚
â”‚   (sequences + metadata + zero vectors)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: Embedding Generation              â”‚
â”‚                                             â”‚
â”‚  Tokenization â”€â”€> NT-500M â”€â”€> Mean Pooling â”‚
â”‚  (CharToken)     (Forward Pass)  (768-dim) â”‚
â”‚      â†“               â†“              â†“       â”‚
â”‚   [A,T,G,C]    [GPU/CPU]      [embedding] â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                     â†“                       â”‚
â”‚              LanceDB Update                â”‚
â”‚      (sequences + embeddings)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: Novelty Detection (NEXT)           â”‚
â”‚                                             â”‚
â”‚  HDBSCAN â”€â”€> Novelty â”€â”€> Taxonomy          â”‚
â”‚  (clustering) (scoring)   (assignment)     â”‚
â”‚      â†“          â†“          â†“               â”‚
â”‚   clusters  scores     lineages            â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                 â†“                          â”‚
â”‚          LanceDB Update                   â”‚
â”‚    (novelty_score, cluster_id, etc.)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4: Visualization (NEXT)               â”‚
â”‚                                             â”‚
â”‚  Streamlit Dashboard                       â”‚
â”‚  â”œâ”€ Dashboard (summary stats)             â”‚
â”‚  â”œâ”€ Embedding Explorer (UMAP)             â”‚
â”‚  â”œâ”€ Vector Search                         â”‚
â”‚  â”œâ”€ Novelty Detection                     â”‚
â”‚  â”œâ”€ Diversity Metrics                     â”‚
â”‚  â””â”€ Configuration                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Next: Taxonomy & Novelty Detection

Ready to implement Phase 3?

Key components to add to `src/edge/taxonomy.py`:
1. `TaxonomyEngine.cluster_embeddings()` - HDBSCAN
2. `TaxonomyEngine.compute_novelty_scores()` - Distance-based
3. `TaxonomyEngine.assign_taxonomy()` - Consensus voting
4. `TaxonomyEngine.compute_diversity()` - Shannon/Simpson
5. LanceDB update logic for novel taxa

See [agents.md](agents.md) for role assignments.
